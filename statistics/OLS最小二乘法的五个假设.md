# OLS最小二乘法的五个假设
----

OLS回归的五个假设：
1. 线性假设：因变量为一组自变量的线性函数加上干扰项。违反该假设成为设定误差。通常有（a）错误回归元；（b）非线性；（c）参数改变。
2. 干扰项期望值为零。 违背是称为截距偏误问题。
3. 所有干扰项具有相同的方差，无自相关且相互独立。违背这一假定会出现两大计量经济学问题，即异方差和自相关误差。
4. 自变量的观测结果在重复样本中可以被认为是固定的，或者重复抽取具有相同自变量值得样本是可能的。违背时可能有三种情况：自变量度量误差，自回归和联立方程估计。
5. 观测结果的个数多于自变量的个数，同时不存在完全共线性。多重共线性问题。

以上即为**小样本OLS**的基本假定，针对**大样本**，OLS的假定有一些放松，具体要求如下：

线性假设（不变）
渐近独立的平稳过程（保证样本均值是总体均值的无偏估计）
同期外生性（不再要求扰动项对所有解释变量条件期望为0，只是要求扰动项对同期的解释变量条件期望为0）
无严格多重共线性（不变）

OLS估计量作为其他所有的估计量用来比较的标准器原因是如下的八点：
1. 计算成本。
2. 最小二乘。 OLS估计量就是用来是残差的平方和最小，OLS估计量在这一准则上很自然是“最优的”
3. 最大的R2。 由于OLS估计量在最小二乘准则下是最优的，自然在R2上也是最优
4. 无偏性。 假设显示了OLS估计量是真实值的无偏估计量
5. 最优无偏性。 具有最小的方差-协方差矩阵
6. 均方误差。
7. 渐进准则。 在CLR模型的背景下，OLS模型估计量是无偏的，因此在无限大的样本中它也是无偏的，即渐进无偏